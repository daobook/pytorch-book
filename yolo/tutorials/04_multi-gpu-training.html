
<!DOCTYPE html>

<html lang="zh">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multi-GPU Training</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/tabs.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "xinetzone/pytorch-book");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "ğŸ’¬ comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://xinetzone.github.io/pytorch-book/yolo/tutorials/04_multi-gpu-training.html" />
    <link rel="shortcut icon" href="../../_static/page-logo.jfif"/>
    <link rel="index" title="ç´¢å¼•" href="../../genindex.html" />
    <link rel="search" title="æœç´¢" href="../../search.html" />
    <link rel="next" title="PyTorch Hub" href="05_pytorch-hub.html" />
    <link rel="prev" title="Supervisely Ecosystem ğŸ†•" href="03_supervisely-ecosystem.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="zh">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.jpg" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="æœç´¢è¿™æœ¬ä¹¦..." aria-label="æœç´¢è¿™æœ¬ä¹¦..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  åŸºç¡€
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../start/index.html">
   PyTorch åŸºç¡€
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../start/00_quickly-study.html">
     å¿«é€Ÿå…¥é—¨
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../start/01_tensor.html">
     å¼ é‡
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../start/02_data.html">
     Dataset å’Œ Dataloader
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../start/03_transforms.html">
     å˜æ¢
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../start/04_build-model.html">
     æ„å»ºç¥ç»ç½‘ç»œ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../start/05_autograd.html">
     è‡ªåŠ¨å¾®åˆ†
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  è®¡ç®—æœºè§†è§‰
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../object-detection/index.html">
   ç›®æ ‡æ£€æµ‹
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../object-detection/fine-tuning.html">
     å¾®è°ƒ
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   YOLO ç³»åˆ—
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../intro.html">
     ç®€ä»‹
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../quick-start.html">
     å¿«é€Ÿå…¥é—¨
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../environments/index.html">
     ç¯å¢ƒ
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../environments/AWS-Quickstart.html">
       Amazon Web Services
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../environments/Docker-Quickstart.html">
       Docker
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../environments/GCP-Quickstart.html">
       Google Cloud Platform
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="index.html">
     æ•™ç¨‹
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="00_train-custom-datasets.html">
       è‡ªå®šä¹‰æ•°æ® ğŸ“Œ
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="01_training-tips-best-results.html">
       Tips for Best Training Results
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="02_weights-and-biasis-logging.html">
       Weights &amp; Biases Logging ğŸ†•
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="03_supervisely-ecosystem.html">
       Supervisely Ecosystem ğŸ†•
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Multi-GPU Training
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="05_pytorch-hub.html">
       PyTorch Hub
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="06_torchscript-onnx-coreml-export.html">
       TorchScript, ONNX, CoreML Export
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="07_test-time-augmentation.html">
       Test-Time Augmentation (TTA)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="08_model-ensembling.html">
       Model Ensembling
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="09_pruning-sparsity.html">
       Model Pruning/Sparsity
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="10_hyperparameter-evolution.html">
       Hyperparameter Evolution
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="11_transfer-learning-froze-layers.html">
       Transfer Learning with Frozen Layers
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../face-mask/index.html">
     å£ç½©è¯†åˆ«
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../face-mask/00_loader.html">
       å‡†å¤‡å·¥ä½œ
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../face-mask/01_train.html">
       æ¨¡å‹è®­ç»ƒ
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../face-mask/test.html">
       å£ç½©è¯†åˆ«æµ‹è¯•
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  å¸®åŠ©
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../other/index.html">
   å‚è€ƒ
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../other/bugs.html">
     PyTorch å¸¸è§ Bug
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../other/object-detection.html">
     ç›®æ ‡æ£€æµ‹å‚è€ƒ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../other/other.html">
     å…¶ä»–
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../glossary/index.html">
   æœ¯è¯­è¡¨
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../glossary/numpy.html">
     NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../glossary/pytorch.html">
     PyTorch è¯æ±‡è¡¨
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  <div class="w3-padding w3-card-4 w3-pale-green">
  <a href="https://github.com/xinetzone" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub"
      data-position="top" data-delay="50">
      <i class="fab fa-github"></i>
  </a>
  <a href="mailto:q735613050@163.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top"
      data-delay="50">
      <i class="fas fa-envelope-open"></i>
  </a>
  <a href="tencent://AddContact/?fromId=50&amp;fromSubId=1&amp;subcmd=all&amp;uin=735613050" class="tooltipped"
      target="_blank" data-tooltip="QQè”ç³»æˆ‘: 735613050" data-position="top" data-delay="50">
      <i class="fab fa-qq"></i>
  </a>
  <a href="https://www.zhihu.com/people/xinetzone" class="tooltipped" target="_blank"
      data-tooltip="å…³æ³¨æˆ‘çš„çŸ¥ä¹: xinetzone" data-position="top" data-delay="50">
      <i class="fab fa-zhihu1">çŸ¥</i>
  </a>
  <a target="_blank" rel="noopener" href="https://www.linkedin.com/in/xinet" class="tooltipped"
      data-tooltip="é¢†è‹±è”ç³»æˆ‘: xinet" data-position="top" data-delay="50">
      <i class="fab fa-linkedin"></i>
  </a>
  <div><a href="https://github.com/xinetzone/pytorch-book">PyTorch Book</a> ç‰ˆæƒæ‰€æœ‰</div>
</div> 

</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="åˆ‡æ¢å¯¼èˆª" aria-controls="site-navigation"
                title="åˆ‡æ¢å¯¼èˆª" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="ä¸‹è½½æ­¤é¡µé¢"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/yolo/tutorials/04_multi-gpu-training.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="ä¸‹è½½æºæ–‡ä»¶" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="åˆ—å°æˆPDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/xinetzone/pytorch-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="æºåº“"><i
                    class="fab fa-github"></i>èµ„æ–™åº“</button></a>
        <a class="issues-button"
            href="https://github.com/xinetzone/pytorch-book/issues/new?title=Issue%20on%20page%20%2Fyolo/tutorials/04_multi-gpu-training.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="æ‰“å¼€ä¸€ä¸ªé—®é¢˜"><i class="fas fa-lightbulb"></i>å…¬å¼€çš„é—®é¢˜</button></a>
        <a class="edit-button" href="https://github.com/xinetzone/pytorch-book/edit/main/docs/yolo/tutorials/04_multi-gpu-training.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="ç¼–è¾‘è¿™ä¸ªé¡µé¢"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="å…¨å±æ¨¡å¼"
        title="å…¨å±æ¨¡å¼"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> å†…å®¹
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#before-you-start">
   Before You Start
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training">
   Training
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#single-gpu">
     Single GPU
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multi-gpu-dataparallel-mode-not-recommended">
     Multi-GPU DataParallel Mode (âš ï¸ not recommended)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multi-gpu-distributeddataparallel-mode-recommended">
     Multi-GPU DistributedDataParallel Mode (âœ… recommended)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#notes">
     Notes
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#results">
   Results
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#faq">
   FAQ
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#environments">
   Environments
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#status">
   Status
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#credits">
   Credits
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Multi-GPU Training</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> å†…å®¹ </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#before-you-start">
   Before You Start
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training">
   Training
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#single-gpu">
     Single GPU
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multi-gpu-dataparallel-mode-not-recommended">
     Multi-GPU DataParallel Mode (âš ï¸ not recommended)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multi-gpu-distributeddataparallel-mode-recommended">
     Multi-GPU DistributedDataParallel Mode (âœ… recommended)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#notes">
     Notes
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#results">
   Results
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#faq">
   FAQ
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#environments">
   Environments
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#status">
   Status
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#credits">
   Credits
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="multi-gpu-training">
<h1>Multi-GPU Training<a class="headerlink" href="#multi-gpu-training" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">Â¶</a></h1>
<p>ğŸ“š This guide explains how to properly use <strong>multiple</strong> GPUs to train a dataset with YOLOv5 ğŸš€ on single or multiple machine(s).</p>
<div class="section" id="before-you-start">
<h2>Before You Start<a class="headerlink" href="#before-you-start" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">Â¶</a></h2>
<p>Clone this repo and install <a class="reference external" href="https://github.com/ultralytics/yolov5/blob/master/requirements.txt">requirements.txt</a> dependencies, including <strong>Python&gt;=3.8</strong> and <strong>PyTorch&gt;=1.7</strong>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/ultralytics/yolov5 <span class="c1"># clone repo</span>
<span class="nb">cd</span> yolov5
pip install -r requirements.txt
</pre></div>
</div>
</div>
<div class="section" id="training">
<h2>Training<a class="headerlink" href="#training" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">Â¶</a></h2>
<p>Select a pretrained model to start training from. Here we select <a class="reference external" href="https://github.com/ultralytics/yolov5/blob/master/models/yolov5s.yaml">YOLOv5l</a>, the smallest model available. See our README <a class="reference external" href="https://github.com/ultralytics/yolov5#pretrained-checkpoints">table</a> for a full comparison of all models. We will train this model with Multi-GPU on the <a class="reference external" href="https://github.com/ultralytics/yolov5/blob/master/data/get_coco2017.sh">COCO</a> dataset.</p>
<p align="center"><img width="700" alt="YOLOv5 Models" src="https://user-images.githubusercontent.com/26833433/103595982-ab986000-4eb1-11eb-8c57-4726261b0a88.png"></p>
<div class="section" id="single-gpu">
<h3>Single GPU<a class="headerlink" href="#single-gpu" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">Â¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python train.py  --batch-size <span class="m">64</span> --data coco.yaml --weights yolov5s.pt --device <span class="m">0</span>
</pre></div>
</div>
</div>
<div class="section" id="multi-gpu-dataparallel-mode-not-recommended">
<h3>Multi-GPU <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#torch.nn.DataParallel">DataParallel</a> Mode (âš ï¸ not recommended)<a class="headerlink" href="#multi-gpu-dataparallel-mode-not-recommended" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">Â¶</a></h3>
<p>You can increase the <code class="docutils literal notranslate"><span class="pre">device</span></code> to use Multiple GPUs in DataParallel mode.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python train.py  --batch-size <span class="m">64</span> --data coco.yaml --weights yolov5s.pt --device <span class="m">0</span>,1
</pre></div>
</div>
<p>This method is slow and barely speeds up training compared to using just 1 GPU.</p>
</div>
<div class="section" id="multi-gpu-distributeddataparallel-mode-recommended">
<h3>Multi-GPU <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#torch.nn.parallel.DistributedDataParallel">DistributedDataParallel</a> Mode (âœ… recommended)<a class="headerlink" href="#multi-gpu-distributeddataparallel-mode-recommended" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">Â¶</a></h3>
<p>You will have to pass <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">torch.distributed.launch</span> <span class="pre">--nproc_per_node</span></code>, followed by the usual arguments.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python -m torch.distributed.launch --nproc_per_node <span class="m">2</span> train.py --batch-size <span class="m">64</span> --data coco.yaml --weights yolov5s.pt
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">--nproc_per_node</span></code> specifies how many GPUs you would like to use. In the example above, it is 2.
<code class="docutils literal notranslate"><span class="pre">--batch-size</span></code> is now the Total batch-size. It will be divided evenly to each GPU. In the example above, it is 64/2=32 per GPU.</p>
<p>The code above will use GPUs <code class="docutils literal notranslate"><span class="pre">0...</span> <span class="pre">(N-1)</span></code>.</p>
<details>
    <summary>Use specific GPUs (click to expand)</summary><br>
<p>You can do so by simply passing <code class="docutils literal notranslate"><span class="pre">--device</span></code> followed by your specific GPUs. For example, in the code below, we will use GPUs <code class="docutils literal notranslate"><span class="pre">2,3</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python -m torch.distributed.launch --nproc_per_node <span class="m">2</span> train.py --batch-size <span class="m">64</span> --data coco.yaml --cfg yolov5s.yaml --weights <span class="s1">&#39;&#39;</span> --device <span class="m">2</span>,3
</pre></div>
</div>
</details>
<details>
    <summary>Use SyncBatchNorm (click to expand)</summary><br>
<p><a class="reference external" href="https://pytorch.org/docs/master/generated/torch.nn.SyncBatchNorm.html">SyncBatchNorm</a> could increase accuracy for multiple gpu training, however, it will slow down training by a significant factor. It is <strong>only</strong> available for Multiple GPU DistributedDataParallel training.</p>
<p>It is best used when the batch-size on <strong>each</strong> GPU is small (&lt;= 8).</p>
<p>To use SyncBatchNorm, simple pass <code class="docutils literal notranslate"><span class="pre">--sync-bn</span></code> to the command like below,</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python -m torch.distributed.launch --nproc_per_node <span class="m">2</span> train.py --batch-size <span class="m">64</span> --data coco.yaml --cfg yolov5s.yaml --weights <span class="s1">&#39;&#39;</span> --sync-bn
</pre></div>
</div>
</details>
<details>
    <summary>Use Multiple machines (click to expand)</summary><br>
<p>This is <strong>only</strong> available for Multiple GPU DistributedDataParallel training.</p>
<p>Before we continue, make sure the files on all machines are the same, dataset, codebase, etc. Afterwards, make sure the machines can communicate to each other.</p>
<p>You will have to choose a master machine(the machine that the others will talk to). Note down its address(<code class="docutils literal notranslate"><span class="pre">master_addr</span></code>) and choose a port(<code class="docutils literal notranslate"><span class="pre">master_port</span></code>). I will use <code class="docutils literal notranslate"><span class="pre">master_addr</span> <span class="pre">=</span> <span class="pre">192.168.1.1</span></code> and <code class="docutils literal notranslate"><span class="pre">master_port</span> <span class="pre">=</span> <span class="pre">1234</span></code> for the example below.</p>
<p>To use it, you can do as the following,</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># On master machine 0</span>
$ python -m torch.distributed.launch --nproc_per_node G --nnodes N --node_rank <span class="m">0</span> --master_addr <span class="s2">&quot;192.168.1.1&quot;</span> --master_port <span class="m">1234</span> train.py --batch-size <span class="m">64</span> --data coco.yaml --cfg yolov5s.yaml --weights <span class="s1">&#39;&#39;</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># On machine R</span>
$ python -m torch.distributed.launch --nproc_per_node G --nnodes N --node_rank R --master_addr <span class="s2">&quot;192.168.1.1&quot;</span> --master_port <span class="m">1234</span> train.py --batch-size <span class="m">64</span> --data coco.yaml --cfg yolov5s.yaml --weights <span class="s1">&#39;&#39;</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">G</span></code> is number of GPU per machine, <code class="docutils literal notranslate"><span class="pre">N</span></code> is the number of machines, and <code class="docutils literal notranslate"><span class="pre">R</span></code> is the machine number from <code class="docutils literal notranslate"><span class="pre">0...(N-1)</span></code>.
Letâ€™s say I have two machines with two GPUs each, it would be <code class="docutils literal notranslate"><span class="pre">G</span> <span class="pre">=</span> <span class="pre">2</span></code> , <code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">=</span> <span class="pre">2</span></code>, and <code class="docutils literal notranslate"><span class="pre">R</span> <span class="pre">=</span> <span class="pre">1</span></code> for the above.</p>
<p>Training will not start until <b>all </b> <code class="docutils literal notranslate"><span class="pre">N</span></code> machines are connected. Output will only be shown on master machine!</p>
</details>
</div>
<div class="section" id="notes">
<h3>Notes<a class="headerlink" href="#notes" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">Â¶</a></h3>
<ul class="simple">
<li><p>This does not work on Windows!</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batch-size</span></code> must be a multiple of the number of GPUs!</p></li>
<li><p>GPU 0 will take more memory than the other GPUs. (Edit: After 1.6 pytorch update, it may take even more memory.)</p></li>
<li><p>If you get <code class="docutils literal notranslate"><span class="pre">RuntimeError:</span> <span class="pre">Address</span> <span class="pre">already</span> <span class="pre">in</span> <span class="pre">use</span></code>, it could be because you are running multiple trainings at a time. To fix this, simply use a different port number by adding <code class="docutils literal notranslate"><span class="pre">--master_port</span></code> like below,</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python -m torch.distributed.launch --master_port <span class="m">1234</span> --nproc_per_node <span class="m">2</span> ...
</pre></div>
</div>
</div>
</div>
<div class="section" id="results">
<h2>Results<a class="headerlink" href="#results" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">Â¶</a></h2>
<p>Tested on COCO2017 dataset using V100s for 3 epochs with <code class="docutils literal notranslate"><span class="pre">yolov5l</span></code> and averaged.
DistributedDataParallel mode.</p>
<details>
    <summary>Command</summary>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python train.py --batch-size <span class="m">64</span> --data coco.yaml --cfg yolov5s.yaml --weights <span class="s1">&#39;&#39;</span> --device <span class="m">0</span>
$ python -m torch.distributed.launch --nproc_per_node <span class="m">2</span> train.py --batch-size <span class="m">64</span> --data coco.yaml --weights yolov5s.pt
$ python -m torch.distributed.launch --nproc_per_node <span class="m">4</span> train.py --batch-size <span class="m">64</span> --data coco.yaml --weights yolov5s.pt
$ python -m torch.distributed.launch --nproc_per_node <span class="m">8</span> train.py --batch-size <span class="m">64</span> --data coco.yaml --weights yolov5s.pt
</pre></div>
</div>
</details>
<p><img alt="image" src="https://user-images.githubusercontent.com/9899957/88168921-57702b00-cc45-11ea-8aab-2d020e1e45b9.png" />
<img alt="image" src="https://user-images.githubusercontent.com/9899957/88168932-5b9c4880-cc45-11ea-87cb-1d4b98da61bc.png" /></p>
</div>
<div class="section" id="faq">
<h2>FAQ<a class="headerlink" href="#faq" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">Â¶</a></h2>
<p>If an error occurs, please read the checklist below first! (It could save your time)</p>
<details>
    <summary>Checklist (click to expand) </summary><br>
<ul>
    <li>Have you properly read this post?  </li>
    <li>Have you tried to reclone the codebase? The code changes <b>daily</b>.</li>
    <li>Have you tried to search for your error? Someone may have already encountered it in this repo or in another and have the solution. </li>
    <li>Have you installed all the requirements listed on top (including the correct Python and Pytorch versions)? </li>
    <li>Have you tried in other environments listed in the "Environments" section below? </li>
    <li>Have you tried with another dataset like coco128 or coco2017? It will make it easier to find the root cause. </li>
</ul>
<p>If you went through all the above, feel free to raise an Issue by giving as much detail as possible following the template. <br></p>
</details>
</div>
<div class="section" id="environments">
<h2>Environments<a class="headerlink" href="#environments" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">Â¶</a></h2>
<p>YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including <a class="reference external" href="https://developer.nvidia.com/cuda">CUDA</a>/<a class="reference external" href="https://developer.nvidia.com/cudnn">CUDNN</a>, <a class="reference external" href="https://www.python.org/">Python</a> and <a class="reference external" href="https://pytorch.org/">PyTorch</a> preinstalled):</p>
<ul class="simple">
<li><p><strong>Google Colab and Kaggle</strong> notebooks with free GPU: <a href="https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a> <a href="https://www.kaggle.com/ultralytics/yolov5"><img alt="Open In Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a></p></li>
<li><p><strong>Google Cloud</strong> Deep Learning VM. See <a class="reference external" href="https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart">GCP Quickstart Guide</a></p></li>
<li><p><strong>Amazon</strong> Deep Learning AMI. See <a class="reference external" href="https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart">AWS Quickstart Guide</a></p></li>
<li><p><strong>Docker Image</strong>. See <a class="reference external" href="https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart">Docker Quickstart Guide</a> <a href="https://hub.docker.com/r/ultralytics/yolov5"><img alt="Docker Pulls" src="https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker" /></a></p></li>
</ul>
</div>
<div class="section" id="status">
<h2>Status<a class="headerlink" href="#status" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">Â¶</a></h2>
<p><img alt="CI CPU testing" src="https://github.com/ultralytics/yolov5/workflows/CI%20CPU%20testing/badge.svg" /></p>
<p>If this badge is green, all <a class="reference external" href="https://github.com/ultralytics/yolov5/actions">YOLOv5 GitHub Actions</a> Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 training (<a class="reference external" href="https://github.com/ultralytics/yolov5/blob/master/train.py">train.py</a>), testing (<a class="reference external" href="https://github.com/ultralytics/yolov5/blob/master/test.py">test.py</a>), inference (<a class="reference external" href="https://github.com/ultralytics/yolov5/blob/master/detect.py">detect.py</a>) and export (<a class="reference external" href="https://github.com/ultralytics/yolov5/blob/master/models/export.py">export.py</a>) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.</p>
</div>
<div class="section" id="credits">
<h2>Credits<a class="headerlink" href="#credits" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">Â¶</a></h2>
<p>I would like to thank &#64;MagicFrogSJTU, who did all the heavy lifting, and &#64;glenn-jocher for guiding us along the way.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "xinetzone/pytorch-book",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./yolo/tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="03_supervisely-ecosystem.html" title="ä¸Šä¸€é¡µ é¡µ">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">ä¸Šä¸€é¡µ</p>
            <p class="prev-next-title">Supervisely Ecosystem ğŸ†•</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="05_pytorch-hub.html" title="ä¸‹ä¸€é¡µ é¡µ">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">ä¸‹ä¸€é¡µ</p>
        <p class="prev-next-title">PyTorch Hub</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      é€šè¿‡ xinetzone<br/>
    
        &copy; ç‰ˆæƒ 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>