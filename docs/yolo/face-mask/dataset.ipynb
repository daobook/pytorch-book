{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 口罩识别\n",
    "\n",
    "导入模块："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from utils.file import mkdir, glob_file, gen_dataset, make_yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(r'E:\\kaggle\\datasets\\face-mask-detection')\n",
    "annotations_path = root/'annotations'\n",
    "images_path =  root/'images'\n",
    "\n",
    "annotations_files = glob_file(root, '*.xml')\n",
    "images_files = glob_file(root, '*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['E:/kaggle/datasets/face-mask-detection/annotations/maksssksksss0.xml',\n",
       "  'E:/kaggle/datasets/face-mask-detection/annotations/maksssksksss1.xml',\n",
       "  'E:/kaggle/datasets/face-mask-detection/annotations/maksssksksss2.xml',\n",
       "  'E:/kaggle/datasets/face-mask-detection/annotations/maksssksksss3.xml',\n",
       "  'E:/kaggle/datasets/face-mask-detection/annotations/maksssksksss4.xml'],\n",
       " ['E:/kaggle/datasets/face-mask-detection/images/maksssksksss0.png',\n",
       "  'E:/kaggle/datasets/face-mask-detection/images/maksssksksss1.png',\n",
       "  'E:/kaggle/datasets/face-mask-detection/images/maksssksksss2.png',\n",
       "  'E:/kaggle/datasets/face-mask-detection/images/maksssksksss3.png',\n",
       "  'E:/kaggle/datasets/face-mask-detection/images/maksssksksss4.png'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_files[:5], images_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集制作\n",
    "\n",
    "参考：https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data#3-organize-directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = Path('datasets')\n",
    "mkdir(config_dir)\n",
    "labels = ['with_mask', 'mask_weared_incorrect', 'without_mask']\n",
    "yaml_path = config_dir/'config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.file import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(paths, save_path):\n",
    "    with open(save_path, 'w') as fp:\n",
    "        for path in paths:\n",
    "            fp.write(path+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "(images_train, labels_train), (images_val, labels_val), (images_test, labels_test) = \\\n",
    "        split(images_files, annotations_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(images_train, config_dir/'train.txt')\n",
    "write(images_val, config_dir/'val.txt')\n",
    "write(images_test, config_dir/'test.txt')\n",
    "\n",
    "make_yaml(config_dir.absolute().as_posix(), labels, yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_name = 'yolov5l'\n",
    "image_size = 640\n",
    "batch_size = 4\n",
    "epochs = 10\n",
    "device = '1' if torch.cuda.is_available() else 'cpu'\n",
    "saved_model_name = 'best.pt'\n",
    "\n",
    "# for test\n",
    "confidence_threshold = 0.25 # Threshold of object inference\n",
    "iou_threshold = 0.45 # Threshold of remove overlapping boxes\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wandb online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_path = \"E:/kaggle/yolov5/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com.cnpmjs.org/daobook/yolov5 \n",
      "\n",
      "\n",
      "WARNING: Dataset not found, nonexistent paths: ['E:\\\\kaggle\\\\pytorch-book\\\\docs\\\\yolo\\\\yolov5\\\\datasets\\\\val']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l.pt, cfg=, data=datasets\\config.yaml, hyp=..\\..\\..\\..\\yolov5\\data\\hyps\\hyp.scratch.yaml, epochs=10, batch_size=4, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=1, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=..\\..\\..\\..\\yolov5\\runs\\train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "YOLOv5  v6.0-189-gaf00134 torch 1.10.0 CUDA:1 (NVIDIA GeForce GTX 1080 Ti, 11264MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ..\\..\\..\\..\\yolov5\\runs\\train', view at http://localhost:6006/\n",
      "wandb: Currently logged in as: xinetzone (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "wandb: Tracking run with wandb version 0.10.32\n",
      "wandb: Syncing run pious-sponge-15\n",
      "wandb:  View project at https://wandb.ai/xinetzone/train\n",
      "wandb:  View run at https://wandb.ai/xinetzone/train/runs/2cp0ljai\n",
      "wandb: Run data is saved locally in E:\\kaggle\\pytorch-book\\docs\\yolo\\yolov5\\wandb\\run-20220114_145121-2cp0ljai\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\kaggle\\yolov5\\train.py\", line 636, in <module>\n",
      "    main(opt)\n",
      "  File \"E:\\kaggle\\yolov5\\train.py\", line 533, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"E:\\kaggle\\yolov5\\train.py\", line 95, in train\n",
      "    loggers = Loggers(save_dir, weights, opt, hyp, LOGGER)  # loggers instance\n",
      "  File \"E:\\kaggle\\yolov5\\utils\\loggers\\__init__.py\", line 73, in __init__\n",
      "    self.wandb = WandbLogger(self.opt, run_id)\n",
      "  File \"E:\\kaggle\\yolov5\\utils\\loggers\\wandb\\wandb_utils.py\", line 180, in __init__\n",
      "    self.data_dict = check_wandb_dataset(opt.data)\n",
      "  File \"E:\\kaggle\\yolov5\\utils\\loggers\\wandb\\wandb_utils.py\", line 56, in check_wandb_dataset\n",
      "    return check_dataset(data_file)\n",
      "  File \"E:\\kaggle\\yolov5\\utils\\general.py\", line 427, in check_dataset\n",
      "    raise Exception('Dataset not found.')\n",
      "Exception: Dataset not found.\n",
      "wandb: Waiting for W&B process to finish, PID 20912\n",
      "wandb: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
      "wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)\n",
      "wandb: \\ 0.00MB of 0.00MB uploaded (0.00MB deduped)\n",
      "wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)\n",
      "wandb: / 0.00MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: - 0.00MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: \\ 0.00MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: | 0.00MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: \\ 0.01MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: \\ 0.01MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: \\ 0.01MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)\n",
      "wandb:                                                                                \n",
      "wandb: Find user logs for this run at: E:\\kaggle\\pytorch-book\\docs\\yolo\\yolov5\\wandb\\run-20220114_145121-2cp0ljai\\logs\\debug.log\n",
      "wandb: Find internal logs for this run at: E:\\kaggle\\pytorch-book\\docs\\yolo\\yolov5\\wandb\\run-20220114_145121-2cp0ljai\\logs\\debug-internal.log\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: \n",
      "wandb: Synced pious-sponge-15: https://wandb.ai/xinetzone/train/runs/2cp0ljai\n"
     ]
    }
   ],
   "source": [
    "!python {yolo_path}train.py --weights {model_name}.pt \\\n",
    "        --data {yaml_path} \\\n",
    "        --epochs {epochs} --batch-size {batch_size} \\\n",
    "        --img-size {image_size} --device {device}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = 'runs/train/exp/weights/' + saved_model_name\n",
    "submission_path = 'submission/'\n",
    "mkdir(submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv {saved_model} {submission_path}{saved_model_name}\n",
    "!rm -rf {pwd}runs/train/*\n",
    "!ls {submission_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {yolo_path}detect.py --weights {submission_path}{saved_model_name} \\\n",
    "        --source {new_images_path + sub_directories[2]} --img-size {image_size} \\\n",
    "        --conf-thres {confidence_threshold} --iou-thres {iou_threshold} --device {device} \\\n",
    "        --hide-labels --hide-conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv runs/detect/exp/* {submission_path}\n",
    "!rm -rf runs/detect/*\n",
    "predict_images = [something for something in os.listdir(submission_path) if not os.path.isdir(submission_path + something) and something.endswith('.png')]\n",
    "predict_images.sort(key = lambda e: int(re.sub('[^0-9]', '', e)))\n",
    "predict_images"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91729c9a28b52734f57b710b306c58b64be9d1e1e07c58fcc763d6d7bdf51c2c"
  },
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
