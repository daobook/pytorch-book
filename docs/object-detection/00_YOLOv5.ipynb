{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# YOLOV5\r\n",
    "\r\n",
    "å‚è€ƒï¼š[YOLOv5 | PyTorch](https://pytorch.org/hub/ultralytics_yolov5/)\r\n",
    "\r\n",
    "![](https://zenodo.org/badge/264818686.svg)\r\n",
    "\r\n",
    "## å¼€å§‹ä¹‹å‰çš„å·¥ä½œ\r\n",
    "\r\n",
    "ä»å®‰è£…äº† `PyTorch>=1.7` çš„ `Python>=3.8` ç¯å¢ƒå¼€å§‹ã€‚å®‰è£… YOLOv5 ä¾èµ–é¡¹ï¼š\r\n",
    "\r\n",
    "```shell\r\n",
    "git clone https://github.com/ultralytics/yolov5\r\n",
    "cd yolov5\r\n",
    "pip install -r requirements.txt\r\n",
    "```\r\n",
    "\r\n",
    "## æ¨¡å‹æè¿°\r\n",
    "\r\n",
    "![](./images/model_comparison.png)\r\n",
    "\r\n",
    "- [YOLOv5](https://ultralytics.com/yolov5)ğŸš€æ˜¯ä¸€ä¸ªåœ¨ COCO æ•°æ®é›†ä¸Šè®­ç»ƒçš„å¤åˆç¼©æ”¾ç›®æ ‡æ£€æµ‹æ¨¡å‹ç³»åˆ—ï¼ŒåŒ…æ‹¬æµ‹è¯•æ—¶é—´å¢å¼ºï¼ˆTest Time Augmentationï¼ŒTTAï¼‰ã€æ¨¡å‹é›†æˆã€è¶…å‚æ•°æ¼”åŒ–å’Œå¯¼å‡ºåˆ° ONNXã€CoreML å’Œ TFLite çš„ç®€å•åŠŸèƒ½ã€‚\r\n",
    "- YOLOv5ğŸš€æ˜¯ä¸€ä¸ªç›®æ ‡æ£€æµ‹ä½“ç³»ç»“æ„å’Œæ¨¡å‹çš„å®¶åº­é¢„è®­ç»ƒçš„å¯å¯æ•°æ®é›†ï¼Œå¹¶ä»£è¡¨äº† [Ultralytics](https://ultralytics.com/) å¯¹æœªæ¥è§†è§‰äººå·¥æ™ºèƒ½æ–¹æ³•çš„å¼€æºç ”ç©¶ï¼Œç»“åˆäº†ç»éªŒæ•™è®­å’Œåœ¨æ•°åƒå°æ—¶çš„ç ”ç©¶å’Œå¼€å‘æ¼”å˜çš„æœ€ä½³å®è·µã€‚\r\n",
    "\r\n",
    "| Model | size <sup>(pixels)</sup> | mAP<sup>val 0.5:0.95</sup> | mAP<sup>test 0.5:0.95</sup> | mAP<sup>val 0.5</sup> | Speed <sup>V100 (ms)</sup> | Â  | params <sup>(M)</sup> | FLOPS <sup>640 (B)</sup> |\r\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\r\n",
    "| [YOLOv5s6](https://github.com/ultralytics/yolov5/releases) | 1280 | 43.3 | 43.3 | 61.9 | **4.3** | Â  | 12.7 | 17.4 |\r\n",
    "| [YOLOv5m6](https://github.com/ultralytics/yolov5/releases) | 1280 | 50.5 | 50.5 | 68.7 | 8.4 | Â  | 35.9 | 52.4 |\r\n",
    "| [YOLOv5l6](https://github.com/ultralytics/yolov5/releases) | 1280 | 53.4 | 53.4 | 71.1 | 12.3 | Â  | 77.2 | 117.7 |\r\n",
    "| [YOLOv5x6](https://github.com/ultralytics/yolov5/releases) | 1280 | **54.4** | **54.4** | **72.0** | 22.4 | Â  | 141.8 | 222.9 |\r\n",
    "| [YOLOv5x6](https://github.com/ultralytics/yolov5/releases)Â TTA | 1280 | **55.0** | **55.0** | **72.0** | 70.8 |\r\n",
    "\r\n",
    "* APtest denotes COCO [test-dev2017](http://cocodataset.org/#upload) server results, all other AP results denote val2017 accuracy. * AP values are for single-model single-scale unless otherwise noted. **Reproduce mAP** by `python test.py --data coco.yaml --img 640 --conf 0.001 --iou 0.65` * SpeedGPU averaged over 5000 COCO val2017 images using a GCP [n1-standard-16](https://cloud.google.com/compute/docs/machine-types#n1_standard_machine_types) V100 instance, and includes FP16 inference, postprocessing and NMS. **Reproduce speed** by `python test.py --data coco.yaml --img 640 --conf 0.25 --iou 0.45` * All checkpoints are trained to 300 epochs with default settings and hyperparameters (no autoaugmentation). * Test Time Augmentation ([TTA](https://github.com/ultralytics/yolov5/issues/303)) includes reflection and scale augmentation. **Reproduce TTA** by `python test.py --data coco.yaml --img 1536 --iou 0.7 --augment`\r\n",
    "\r\n",
    "![](./images/model_plot.png)\r\n",
    "\r\n",
    "* GPU Speed measures end-to-end time per image averaged over 5000 COCO val2017 images using a V100 GPU with batch size 32, and includes image preprocessing, PyTorch FP16 inference, postprocessing and NMS. * EfficientDet data from [google/automl](https://github.com/google/automl) at batch size 8. * **Reproduce** by `python test.py --task study --data coco.yaml --iou 0.7 --weights yolov5s6.pt yolov5m6.pt yolov5l6.pt yolov5x6.pt`\r\n",
    "\r\n",
    "æœ‰å…³è®­ç»ƒã€æµ‹è¯•å’Œéƒ¨ç½²çš„å®Œæ•´æ–‡æ¡£ï¼Œè¯·å‚è§ [YOLOv5 æ–‡æ¡£](https://docs.ultralytics.com/)ã€‚\r\n",
    "\r\n",
    "## æ¨ç†\r\n",
    "\r\n",
    "ä½¿ç”¨ YOLOv5å’Œ [PyTorch Hub](https://github.com/ultralytics/yolov5/issues/36) çš„æ¨ç†ã€‚ä»[æœ€æ–°çš„ YOLOv5 ç‰ˆæœ¬](https://github.com/ultralytics/yolov5/releases)è‡ªåŠ¨ä¸‹è½½æ¨¡å‹ã€‚\r\n",
    "\r\n",
    "è¿™ä¸ªç¤ºä¾‹åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒçš„ YOLOv5s æ¨¡å‹ï¼Œå¹¶ä¼ é€’ä¸€ä¸ªç”¨äºæ¨æ–­çš„å›¾åƒã€‚YOLOv5 æ¥å— **URL**, **Filename**, **PIL**, **OpenCV**, **Numpy** å’Œ **PyTorch** è¾“å…¥ï¼Œå¹¶è¿”å›æ£€æµ‹ torchã€pandas å’Œ JSON è¾“å‡ºæ ¼å¼ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§ [YOLOv5 PyTorch Hub æ•™ç¨‹](https://github.com/ultralytics/yolov5/issues/36)ã€‚"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "\r\n",
    "torch.hub.set_dir('../../models/') # è®¾ç½®æ¨¡å‹ä¿æŒç›®å½•\r\n",
    "# æ¨¡å‹\r\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5m, yolov5x, custom\r\n",
    "\r\n",
    "# Images\r\n",
    "# https://ultralytics.com/images/zidane.jpg\r\n",
    "img = 'images/zidane.jpg'  # or file, PIL, OpenCV, numpy, multiple\r\n",
    "\r\n",
    "# Inference\r\n",
    "results = model(img)\r\n",
    "\r\n",
    "# Results\r\n",
    "results.print()  # or .show(), .save(), .crop(), .pandas(), etc.\r\n",
    "\r\n",
    "results.xyxy[0]  # img1 predictions (tensor)\r\n",
    "results.pandas().xyxy[0]  # img1 predictions (pandas)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using cache found in ../../models/ultralytics_yolov5_master\n",
      "Fusing layers... \n",
      "C:\\Users\\xinet\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Model Summary: 224 layers, 7266973 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "YOLOv5  92bc73f torch 1.9.0 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11264.0MB)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "image 1/1: 720x1280 2 persons, 2 ties\n",
      "Speed: 38.8ms pre-process, 1147.4ms inference, 11.0ms NMS per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750.0</td>\n",
       "      <td>43.00</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>0.876953</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433.5</td>\n",
       "      <td>434.00</td>\n",
       "      <td>518.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>0.658203</td>\n",
       "      <td>27</td>\n",
       "      <td>tie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113.5</td>\n",
       "      <td>196.25</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>0.596191</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>986.0</td>\n",
       "      <td>304.50</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0.284668</td>\n",
       "      <td>27</td>\n",
       "      <td>tie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    xmin    ymin    xmax   ymax  confidence  class    name\n",
       "0  750.0   43.00  1148.0  709.0    0.876953      0  person\n",
       "1  433.5  434.00   518.0  715.0    0.658203     27     tie\n",
       "2  113.5  196.25  1092.0  710.0    0.596191      0  person\n",
       "3  986.0  304.50  1028.0  420.0    0.284668     27     tie"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ä½¿ç”¨ `detect.py` æ¨ç†\r\n",
    "\r\n",
    "`detect.py` å¯¹å„ç§æºè¿è¡Œæ¨æ–­ï¼Œè‡ªåŠ¨ä»[æœ€æ–°çš„ YOLOv5 ç‰ˆæœ¬](https://github.com/ultralytics/yolov5/releases)ä¸‹è½½æ¨¡å‹ï¼Œå¹¶å°†ç»“æœä¿å­˜åˆ° `runs/detect`ã€‚\r\n",
    "\r\n",
    "```shell\r\n",
    "python detect.py --source 0  # webcam\r\n",
    "                            file.jpg  # image \r\n",
    "                            file.mp4  # video\r\n",
    "                            path/  # directory\r\n",
    "                            path/*.jpg  # glob\r\n",
    "                            'https://youtu.be/NUsoVlDFqZg'  # YouTube video\r\n",
    "                            'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\r\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## è®­ç»ƒ\r\n",
    "\r\n",
    "è¿è¡Œä¸‹é¢çš„å‘½ä»¤åœ¨ COCO æ•°æ®é›†ä¸Šé‡ç°ç»“æœï¼ˆæ•°æ®é›†ç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨ä¸‹è½½ï¼‰ã€‚åœ¨å•ä¸ªV100ä¸Šï¼ŒYOLOv5s/m/l/xçš„åŸ¹è®­æ—¶é—´æ˜¯2/4/6/8å¤©ï¼ˆå¤š gpu æ›´å¿«ï¼‰ã€‚ä½¿ç”¨ GPU å…è®¸çš„æœ€å¤§æ‰¹å¤„ç†å¤§å°ï¼ˆ16GBè®¾å¤‡çš„æ‰¹å¤„ç†å¤§å°ï¼‰ã€‚\r\n",
    "\r\n",
    "```shell\r\n",
    "python train.py --data coco.yaml --cfg yolov5s.yaml --weights '' --batch-size 64\r\n",
    "                                         yolov5m                                40\r\n",
    "                                         yolov5l                                24\r\n",
    "                                         yolov5x                                16\r\n",
    "```\r\n",
    "\r\n",
    "![](./images/coco-yolov5.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst,ipynb"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('torch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "interpreter": {
   "hash": "b9674a63e071d82efc24a7bd55c3399e0be8bf8ee990a2a97fd04d90977e4f42"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}