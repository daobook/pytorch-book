{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25799147",
   "metadata": {},
   "source": [
    "# YOLOV5\n",
    "\n",
    "参考：[YOLOv5 | PyTorch](https://pytorch.org/hub/ultralytics_yolov5/)\n",
    "\n",
    "![](https://zenodo.org/badge/264818686.svg)\n",
    "\n",
    "## 开始之前的工作\n",
    "\n",
    "从安装了 `PyTorch>=1.7` 的 `Python>=3.8` 环境开始。安装 YOLOv5 依赖项：\n",
    "\n",
    "```shell\n",
    "$ git clone https://github.com/ultralytics/yolov5\n",
    "$ cd yolov5\n",
    "$ pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## 模型描述\n",
    "\n",
    "![](./images/model_comparison.png)\n",
    "\n",
    "- [YOLOv5](https://ultralytics.com/yolov5)🚀是一个在 COCO 数据集上训练的复合缩放目标检测模型系列，包括测试时间增强（Test Time Augmentation，TTA）、模型集成、超参数演化和导出到 ONNX、CoreML 和 TFLite 的简单功能。\n",
    "- YOLOv5🚀是一个目标检测体系结构和模型的家庭预训练的可可数据集，并代表了 [Ultralytics](https://ultralytics.com/) 对未来视觉人工智能方法的开源研究，结合了经验教训和在数千小时的研究和开发演变的最佳实践。\n",
    "\n",
    "| Model | size <sup>(pixels)</sup> | mAP<sup>val 0.5:0.95</sup> | mAP<sup>test 0.5:0.95</sup> | mAP<sup>val 0.5</sup> | Speed <sup>V100 (ms)</sup> |   | params <sup>(M)</sup> | FLOPS <sup>640 (B)</sup> |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| [YOLOv5s6](https://github.com/ultralytics/yolov5/releases) | 1280 | 43.3 | 43.3 | 61.9 | **4.3** |   | 12.7 | 17.4 |\n",
    "| [YOLOv5m6](https://github.com/ultralytics/yolov5/releases) | 1280 | 50.5 | 50.5 | 68.7 | 8.4 |   | 35.9 | 52.4 |\n",
    "| [YOLOv5l6](https://github.com/ultralytics/yolov5/releases) | 1280 | 53.4 | 53.4 | 71.1 | 12.3 |   | 77.2 | 117.7 |\n",
    "| [YOLOv5x6](https://github.com/ultralytics/yolov5/releases) | 1280 | **54.4** | **54.4** | **72.0** | 22.4 |   | 141.8 | 222.9 |\n",
    "| [YOLOv5x6](https://github.com/ultralytics/yolov5/releases) TTA | 1280 | **55.0** | **55.0** | **72.0** | 70.8 |\n",
    "\n",
    "* APtest denotes COCO [test-dev2017](http://cocodataset.org/#upload) server results, all other AP results denote val2017 accuracy. * AP values are for single-model single-scale unless otherwise noted. **Reproduce mAP** by `python test.py --data coco.yaml --img 640 --conf 0.001 --iou 0.65` * SpeedGPU averaged over 5000 COCO val2017 images using a GCP [n1-standard-16](https://cloud.google.com/compute/docs/machine-types#n1_standard_machine_types) V100 instance, and includes FP16 inference, postprocessing and NMS. **Reproduce speed** by `python test.py --data coco.yaml --img 640 --conf 0.25 --iou 0.45` * All checkpoints are trained to 300 epochs with default settings and hyperparameters (no autoaugmentation). * Test Time Augmentation ([TTA](https://github.com/ultralytics/yolov5/issues/303)) includes reflection and scale augmentation. **Reproduce TTA** by `python test.py --data coco.yaml --img 1536 --iou 0.7 --augment`\n",
    "\n",
    "![](./images/model_plot.png)\n",
    "\n",
    "* GPU Speed measures end-to-end time per image averaged over 5000 COCO val2017 images using a V100 GPU with batch size 32, and includes image preprocessing, PyTorch FP16 inference, postprocessing and NMS. * EfficientDet data from [google/automl](https://github.com/google/automl) at batch size 8. * **Reproduce** by `python test.py --task study --data coco.yaml --iou 0.7 --weights yolov5s6.pt yolov5m6.pt yolov5l6.pt yolov5x6.pt`\n",
    "\n",
    "有关训练、测试和部署的完整文档，请参见 [YOLOv5 文档](https://docs.ultralytics.com/)。\n",
    "\n",
    "## 推理\n",
    "\n",
    "使用 YOLOv5和 [PyTorch Hub](https://github.com/ultralytics/yolov5/issues/36) 的推理。从[最新的 YOLOv5 版本](https://github.com/ultralytics/yolov5/releases)自动下载模型。\n",
    "\n",
    "这个示例加载一个预训练的 YOLOv5s 模型，并传递一个用于推断的图像。YOLOv5 接受 **URL**, **Filename**, **PIL**, **OpenCV**, **Numpy** 和 **PyTorch** 输入，并返回检测火炬，熊猫和JSON输出格式。有关详细信息，请参见我们的YOLOv5 PyTorch Hub教程。\n",
    "这个示例加载一个预训练的 YOLOv5s 模型，并传递一个用于推断的图像。YOLOv5 接受 **URL**, **Filename**, **PIL**, **OpenCV**, **Numpy** 和 **PyTorch** 输入，并返回检测 torch、pandas 和 JSON 输出格式。有关详细信息，请参见 [YOLOv5 PyTorch Hub 教程](https://github.com/ultralytics/yolov5/issues/36)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76bf44f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in ../../models/ultralytics_yolov5_master\n",
      "Fusing layers... \n",
      "C:\\Users\\xinet\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Model Summary: 224 layers, 7266973 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "YOLOv5  92bc73f torch 1.9.0 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11264.0MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 720x1280 2 persons, 2 ties\n",
      "Speed: 38.8ms pre-process, 1147.4ms inference, 11.0ms NMS per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750.0</td>\n",
       "      <td>43.00</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>0.876953</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433.5</td>\n",
       "      <td>434.00</td>\n",
       "      <td>518.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>0.658203</td>\n",
       "      <td>27</td>\n",
       "      <td>tie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113.5</td>\n",
       "      <td>196.25</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>0.596191</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>986.0</td>\n",
       "      <td>304.50</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0.284668</td>\n",
       "      <td>27</td>\n",
       "      <td>tie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    xmin    ymin    xmax   ymax  confidence  class    name\n",
       "0  750.0   43.00  1148.0  709.0    0.876953      0  person\n",
       "1  433.5  434.00   518.0  715.0    0.658203     27     tie\n",
       "2  113.5  196.25  1092.0  710.0    0.596191      0  person\n",
       "3  986.0  304.50  1028.0  420.0    0.284668     27     tie"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.hub.set_dir('../../models/') # 设置模型保持目录\n",
    "# 模型\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5m, yolov5x, custom\n",
    "\n",
    "# Images\n",
    "# https://ultralytics.com/images/zidane.jpg\n",
    "img = 'images/zidane.jpg'  # or file, PIL, OpenCV, numpy, multiple\n",
    "\n",
    "# Inference\n",
    "results = model(img)\n",
    "\n",
    "# Results\n",
    "results.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n",
    "\n",
    "results.xyxy[0]  # img1 predictions (tensor)\n",
    "results.pandas().xyxy[0]  # img1 predictions (pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59fd584",
   "metadata": {},
   "source": [
    "### 使用 `detect.py` 推理\n",
    "\n",
    "`detect.py` 对各种源运行推断，自动从[最新的 YOLOv5 版本](https://github.com/ultralytics/yolov5/releases)下载模型，并将结果保存到`runs/detect`。\n",
    "\n",
    "```shell\n",
    "$ python detect.py --source 0  # webcam\n",
    "                            file.jpg  # image \n",
    "                            file.mp4  # video\n",
    "                            path/  # directory\n",
    "                            path/*.jpg  # glob\n",
    "                            'https://youtu.be/NUsoVlDFqZg'  # YouTube video\n",
    "                            'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d189e90",
   "metadata": {},
   "source": [
    "## 训练\n",
    "\n",
    "运行下面的命令在 COCO 数据集上重现结果（数据集第一次使用时自动下载）。在单个V100上，YOLOv5s/m/l/x的培训时间是2/4/6/8天（多 gpu 更快）。使用 GPU 允许的最大批处理大小（16GB设备的批处理大小）。\n",
    "\n",
    "```shell\n",
    "$ python train.py --data coco.yaml --cfg yolov5s.yaml --weights '' --batch-size 64\n",
    "                                         yolov5m                                40\n",
    "                                         yolov5l                                24\n",
    "                                         yolov5x                                16\n",
    "```\n",
    "\n",
    "![](./images/coco-yolov5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccecfbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst,ipynb"
  },
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
